{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWdIgWwOq3t0CCU6sf7Sot",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youssefawwad88/Tradingstation/blob/main/Trading_Station.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "#  MASTER SETUP CELL - Run this ONCE every time you start a new session\n",
        "# ===============================================================\n",
        "\n",
        "# 1. Connect to your permanent storage in Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Load your secret API key into the environment for our scripts to use\n",
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['ALPHA_VANTAGE_API_KEY'] = userdata.get('ALPHA_VANTAGE_API_KEY')\n",
        "\n",
        "# 3. Install any Python libraries that Colab doesn't have by default\n",
        "!pip install schedule pytz pandas requests -q\n",
        "\n",
        "print(\"\\n✅ Environment setup complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ9ZyjaDzC-p",
        "outputId": "0d48dc63-6027-46ee-dd4e-124ea3d7f233"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "✅ Environment setup complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Command: Execute the Data Fetcher\n",
        "This command runs the update_all_data.py script. The script's job is to read your tickerlist.txt file, then loop through each ticker and fetch the complete daily, 30-minute, and 1-minute data from the Alpha Vantage API. It then saves this data into organized CSV files within your Google Drive.\n",
        "\n",
        "What to Expect: You will see a series of print statements in the output as it processes each ticker and data type. This is the initial \"bulk download\" of your data."
      ],
      "metadata": {
        "id": "3la-zhyc-yad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/drive/MyDrive/trading-system/jobs/update_all_data.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4gYCYOpxiQ_",
        "outputId": "c9f8e0ea-69f8-4375-8ba2-4a307e555a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 8 tickers from tickerlist.txt\n",
            "Verifying project directories...\n",
            "All directories are present in Google Drive.\n",
            "--- Starting Full Market Data Update ---\n",
            "Processing 8 tickers: ['NVDA', 'AAPL', 'TSLA', 'AMD', 'GOOGL', 'MSFT', 'AMZN', 'NFLX']\n",
            "\n",
            "--- Updating data for NVDA ---\n",
            "--> Fetching DAILY data for NVDA...\n",
            "    [✔] Successfully fetched 6471 rows of daily data for NVDA.\n",
            "    Merging data: Found 200 existing rows in NVDA_daily.csv.\n",
            "    Merge complete: Added 6271 new unique row(s). Total rows: 6471.\n",
            "    [✔] Successfully saved data for NVDA to NVDA_daily.csv\n",
            "--> Fetching REAL-TIME 30min data for NVDA...\n",
            "    [✔] Successfully fetched 672 rows for NVDA.\n",
            "    Merging data: Found 500 existing rows in NVDA_30min.csv.\n",
            "    Merge complete: Added 172 new unique row(s). Total rows: 672.\n",
            "    [✔] Successfully saved data for NVDA to NVDA_30min.csv\n",
            "--> Fetching REAL-TIME 1min data for NVDA...\n",
            "    [✔] Successfully fetched 20129 rows for NVDA.\n",
            "    Merging data: Found 2730 existing rows in NVDA_1min.csv.\n",
            "    Merge complete: Added 17399 new unique row(s). Total rows: 20129.\n",
            "    [✔] Successfully saved data for NVDA to NVDA_1min.csv\n",
            "\n",
            "--- Updating data for AAPL ---\n",
            "--> Fetching DAILY data for AAPL...\n",
            "    [✔] Successfully fetched 6471 rows of daily data for AAPL.\n",
            "    Merging data: Found 200 existing rows in AAPL_daily.csv.\n",
            "    Merge complete: Added 6271 new unique row(s). Total rows: 6471.\n",
            "    [✔] Successfully saved data for AAPL to AAPL_daily.csv\n",
            "--> Fetching REAL-TIME 30min data for AAPL...\n",
            "    [✔] Successfully fetched 672 rows for AAPL.\n",
            "    Merging data: Found 500 existing rows in AAPL_30min.csv.\n",
            "    Merge complete: Added 172 new unique row(s). Total rows: 672.\n",
            "    [✔] Successfully saved data for AAPL to AAPL_30min.csv\n",
            "--> Fetching REAL-TIME 1min data for AAPL...\n",
            "    [✔] Successfully fetched 20050 rows for AAPL.\n",
            "    Merging data: Found 2730 existing rows in AAPL_1min.csv.\n",
            "    Merge complete: Added 17320 new unique row(s). Total rows: 20050.\n",
            "    [✔] Successfully saved data for AAPL to AAPL_1min.csv\n",
            "\n",
            "--- Updating data for TSLA ---\n",
            "--> Fetching DAILY data for TSLA...\n",
            "    [✔] Successfully fetched 3791 rows of daily data for TSLA.\n",
            "    Merging data: Found 200 existing rows in TSLA_daily.csv.\n",
            "    Merge complete: Added 3591 new unique row(s). Total rows: 3791.\n",
            "    [✔] Successfully saved data for TSLA to TSLA_daily.csv\n",
            "--> Fetching REAL-TIME 30min data for TSLA...\n",
            "    [✔] Successfully fetched 672 rows for TSLA.\n",
            "    Merging data: Found 500 existing rows in TSLA_30min.csv.\n",
            "    Merge complete: Added 172 new unique row(s). Total rows: 672.\n",
            "    [✔] Successfully saved data for TSLA to TSLA_30min.csv\n",
            "--> Fetching REAL-TIME 1min data for TSLA...\n",
            "    [✔] Successfully fetched 20138 rows for TSLA.\n",
            "    Merging data: Found 2730 existing rows in TSLA_1min.csv.\n",
            "    Merge complete: Added 17408 new unique row(s). Total rows: 20138.\n",
            "    [✔] Successfully saved data for TSLA to TSLA_1min.csv\n",
            "\n",
            "--- Updating data for AMD ---\n",
            "--> Fetching DAILY data for AMD...\n",
            "    [✔] Successfully fetched 6471 rows of daily data for AMD.\n",
            "    Merging data: Found 200 existing rows in AMD_daily.csv.\n",
            "    Merge complete: Added 6271 new unique row(s). Total rows: 6471.\n",
            "    [✔] Successfully saved data for AMD to AMD_daily.csv\n",
            "--> Fetching REAL-TIME 30min data for AMD...\n",
            "    [✔] Successfully fetched 672 rows for AMD.\n",
            "    Merging data: Found 500 existing rows in AMD_30min.csv.\n",
            "    Merge complete: Added 172 new unique row(s). Total rows: 672.\n",
            "    [✔] Successfully saved data for AMD to AMD_30min.csv\n",
            "--> Fetching REAL-TIME 1min data for AMD...\n",
            "    [✔] Successfully fetched 20100 rows for AMD.\n",
            "    Merging data: Found 2730 existing rows in AMD_1min.csv.\n",
            "    Merge complete: Added 17370 new unique row(s). Total rows: 20100.\n",
            "    [✔] Successfully saved data for AMD to AMD_1min.csv\n",
            "\n",
            "--- Updating data for GOOGL ---\n",
            "--> Fetching DAILY data for GOOGL...\n",
            "    [✔] Successfully fetched 5266 rows of daily data for GOOGL.\n",
            "    Merging data: Found 200 existing rows in GOOGL_daily.csv.\n",
            "    Merge complete: Added 5066 new unique row(s). Total rows: 5266.\n",
            "    [✔] Successfully saved data for GOOGL to GOOGL_daily.csv\n",
            "--> Fetching REAL-TIME 30min data for GOOGL...\n",
            "    [✔] Successfully fetched 672 rows for GOOGL.\n",
            "    Merging data: Found 500 existing rows in GOOGL_30min.csv.\n",
            "    Merge complete: Added 172 new unique row(s). Total rows: 672.\n",
            "    [✔] Successfully saved data for GOOGL to GOOGL_30min.csv\n",
            "--> Fetching REAL-TIME 1min data for GOOGL...\n",
            "    [✔] Successfully fetched 20050 rows for GOOGL.\n",
            "    Merging data: Found 2730 existing rows in GOOGL_1min.csv.\n",
            "    Merge complete: Added 17320 new unique row(s). Total rows: 20050.\n",
            "    [✔] Successfully saved data for GOOGL to GOOGL_1min.csv\n",
            "\n",
            "--- Updating data for MSFT ---\n",
            "--> Fetching DAILY data for MSFT...\n",
            "    [✔] Successfully fetched 6471 rows of daily data for MSFT.\n",
            "    Merging data: Found 200 existing rows in MSFT_daily.csv.\n",
            "    Merge complete: Added 6271 new unique row(s). Total rows: 6471.\n",
            "    [✔] Successfully saved data for MSFT to MSFT_daily.csv\n",
            "--> Fetching REAL-TIME 30min data for MSFT...\n",
            "    [✔] Successfully fetched 672 rows for MSFT.\n",
            "    Merging data: Found 500 existing rows in MSFT_30min.csv.\n",
            "    Merge complete: Added 172 new unique row(s). Total rows: 672.\n",
            "    [✔] Successfully saved data for MSFT to MSFT_30min.csv\n",
            "--> Fetching REAL-TIME 1min data for MSFT...\n",
            "    [✔] Successfully fetched 19642 rows for MSFT.\n",
            "    Merging data: Found 2730 existing rows in MSFT_1min.csv.\n",
            "    Merge complete: Added 16912 new unique row(s). Total rows: 19642.\n",
            "    [✔] Successfully saved data for MSFT to MSFT_1min.csv\n",
            "\n",
            "--- Updating data for AMZN ---\n",
            "--> Fetching DAILY data for AMZN...\n",
            "    [✔] Successfully fetched 6471 rows of daily data for AMZN.\n",
            "    Merging data: Found 200 existing rows in AMZN_daily.csv.\n",
            "    Merge complete: Added 6271 new unique row(s). Total rows: 6471.\n",
            "    [✔] Successfully saved data for AMZN to AMZN_daily.csv\n",
            "--> Fetching REAL-TIME 30min data for AMZN...\n",
            "    [✔] Successfully fetched 672 rows for AMZN.\n",
            "    Merging data: Found 500 existing rows in AMZN_30min.csv.\n",
            "    Merge complete: Added 172 new unique row(s). Total rows: 672.\n",
            "    [✔] Successfully saved data for AMZN to AMZN_30min.csv\n",
            "--> Fetching REAL-TIME 1min data for AMZN...\n",
            "    [✔] Successfully fetched 19903 rows for AMZN.\n",
            "    Merging data: Found 2730 existing rows in AMZN_1min.csv.\n",
            "    Merge complete: Added 17173 new unique row(s). Total rows: 19903.\n",
            "    [✔] Successfully saved data for AMZN to AMZN_1min.csv\n",
            "\n",
            "--- Updating data for NFLX ---\n",
            "--> Fetching DAILY data for NFLX...\n",
            "    [✔] Successfully fetched 5830 rows of daily data for NFLX.\n",
            "    Merging data: Found 200 existing rows in NFLX_daily.csv.\n",
            "    Merge complete: Added 5630 new unique row(s). Total rows: 5830.\n",
            "    [✔] Successfully saved data for NFLX to NFLX_daily.csv\n",
            "--> Fetching REAL-TIME 30min data for NFLX...\n",
            "    [✔] Successfully fetched 672 rows for NFLX.\n",
            "    Merging data: Found 500 existing rows in NFLX_30min.csv.\n",
            "    Merge complete: Added 172 new unique row(s). Total rows: 672.\n",
            "    [✔] Successfully saved data for NFLX to NFLX_30min.csv\n",
            "--> Fetching REAL-TIME 1min data for NFLX...\n",
            "    [✔] Successfully fetched 18662 rows for NFLX.\n",
            "    Merging data: Found 2730 existing rows in NFLX_1min.csv.\n",
            "    Merge complete: Added 15932 new unique row(s). Total rows: 18662.\n",
            "    [✔] Successfully saved data for NFLX to NFLX_1min.csv\n",
            "\n",
            "--- Full Market Data Update Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Command: Execute the Compact Intraday Updater**\n",
        "This command runs the update_intraday_compact.py script. This script is optimized for frequent, fast updates. It only downloads the last 100 data points from the API and intelligently appends the newest 1-minute and 30-minute candles to your existing CSV files.\n",
        "\n",
        "When to Use: This is the command you will use repeatedly throughout the trading day to keep your intraday data live."
      ],
      "metadata": {
        "id": "48L84_9zRGQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/drive/MyDrive/trading-system/jobs/update_intraday_compact.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4BX9tc-RJRX",
        "outputId": "a7440f14-96d8-4e19-da4c-73a4ced8a118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 8 tickers from tickerlist.txt\n",
            "Verifying project directories...\n",
            "All directories are present in Google Drive.\n",
            "--- Starting Compact Intraday Data Update ---\n",
            "Processing 8 tickers for compact update...\n",
            "\n",
            "--- Updating intraday data for NVDA ---\n",
            "--> Fetching REAL-TIME 30min data for NVDA...\n",
            "    [✔] Successfully fetched 100 rows for NVDA.\n",
            "    Merging data: Found 672 existing rows in NVDA_30min.csv.\n",
            "    Merge complete: Added 0 new unique row(s). Total rows: 672.\n",
            "    [✔] Successfully saved data for NVDA to NVDA_30min.csv\n",
            "--> Fetching REAL-TIME 1min data for NVDA...\n",
            "    [✔] Successfully fetched 100 rows for NVDA.\n",
            "    Merging data: Found 20131 existing rows in NVDA_1min.csv.\n",
            "    Merge complete: Added 3 new unique row(s). Total rows: 20134.\n",
            "    [✔] Successfully saved data for NVDA to NVDA_1min.csv\n",
            "\n",
            "--- Updating intraday data for AAPL ---\n",
            "--> Fetching REAL-TIME 30min data for AAPL...\n",
            "    [✔] Successfully fetched 100 rows for AAPL.\n",
            "    Merging data: Found 672 existing rows in AAPL_30min.csv.\n",
            "    Merge complete: Added 0 new unique row(s). Total rows: 672.\n",
            "    [✔] Successfully saved data for AAPL to AAPL_30min.csv\n",
            "--> Fetching REAL-TIME 1min data for AAPL...\n",
            "    [✔] Successfully fetched 100 rows for AAPL.\n",
            "    Merging data: Found 20051 existing rows in AAPL_1min.csv.\n",
            "    Merge complete: Added 2 new unique row(s). Total rows: 20053.\n",
            "    [✔] Successfully saved data for AAPL to AAPL_1min.csv\n",
            "\n",
            "--- Updating intraday data for TSLA ---\n",
            "--> Fetching REAL-TIME 30min data for TSLA...\n",
            "    [✔] Successfully fetched 100 rows for TSLA.\n",
            "    Merging data: Found 672 existing rows in TSLA_30min.csv.\n",
            "    Merge complete: Added 0 new unique row(s). Total rows: 672.\n",
            "    [✔] Successfully saved data for TSLA to TSLA_30min.csv\n",
            "--> Fetching REAL-TIME 1min data for TSLA...\n",
            "    [✔] Successfully fetched 100 rows for TSLA.\n",
            "    Merging data: Found 20139 existing rows in TSLA_1min.csv.\n",
            "    Merge complete: Added 4 new unique row(s). Total rows: 20143.\n",
            "    [✔] Successfully saved data for TSLA to TSLA_1min.csv\n",
            "\n",
            "--- Updating intraday data for AMD ---\n",
            "--> Fetching REAL-TIME 30min data for AMD...\n",
            "    [✔] Successfully fetched 100 rows for AMD.\n",
            "    Merging data: Found 672 existing rows in AMD_30min.csv.\n",
            "    Merge complete: Added 0 new unique row(s). Total rows: 672.\n",
            "    [✔] Successfully saved data for AMD to AMD_30min.csv\n",
            "--> Fetching REAL-TIME 1min data for AMD...\n",
            "    [✔] Successfully fetched 100 rows for AMD.\n",
            "    Merging data: Found 20101 existing rows in AMD_1min.csv.\n",
            "    Merge complete: Added 3 new unique row(s). Total rows: 20104.\n",
            "    [✔] Successfully saved data for AMD to AMD_1min.csv\n",
            "\n",
            "--- Updating intraday data for GOOGL ---\n",
            "--> Fetching REAL-TIME 30min data for GOOGL...\n",
            "    [✔] Successfully fetched 100 rows for GOOGL.\n",
            "    Merging data: Found 672 existing rows in GOOGL_30min.csv.\n",
            "    Merge complete: Added 0 new unique row(s). Total rows: 672.\n",
            "    [✔] Successfully saved data for GOOGL to GOOGL_30min.csv\n",
            "--> Fetching REAL-TIME 1min data for GOOGL...\n",
            "    [✔] Successfully fetched 100 rows for GOOGL.\n",
            "    Merging data: Found 20051 existing rows in GOOGL_1min.csv.\n",
            "    Merge complete: Added 4 new unique row(s). Total rows: 20055.\n",
            "    [✔] Successfully saved data for GOOGL to GOOGL_1min.csv\n",
            "\n",
            "--- Updating intraday data for MSFT ---\n",
            "--> Fetching REAL-TIME 30min data for MSFT...\n",
            "    [✔] Successfully fetched 100 rows for MSFT.\n",
            "    Merging data: Found 672 existing rows in MSFT_30min.csv.\n",
            "    Merge complete: Added 0 new unique row(s). Total rows: 672.\n",
            "    [✔] Successfully saved data for MSFT to MSFT_30min.csv\n",
            "--> Fetching REAL-TIME 1min data for MSFT...\n",
            "    [✔] Successfully fetched 100 rows for MSFT.\n",
            "    Merging data: Found 19642 existing rows in MSFT_1min.csv.\n",
            "    Merge complete: Added 2 new unique row(s). Total rows: 19644.\n",
            "    [✔] Successfully saved data for MSFT to MSFT_1min.csv\n",
            "\n",
            "--- Updating intraday data for AMZN ---\n",
            "--> Fetching REAL-TIME 30min data for AMZN...\n",
            "    [✔] Successfully fetched 100 rows for AMZN.\n",
            "    Merging data: Found 672 existing rows in AMZN_30min.csv.\n",
            "    Merge complete: Added 0 new unique row(s). Total rows: 672.\n",
            "    [✔] Successfully saved data for AMZN to AMZN_30min.csv\n",
            "--> Fetching REAL-TIME 1min data for AMZN...\n",
            "    [✔] Successfully fetched 100 rows for AMZN.\n",
            "    Merging data: Found 19903 existing rows in AMZN_1min.csv.\n",
            "    Merge complete: Added 5 new unique row(s). Total rows: 19908.\n",
            "    [✔] Successfully saved data for AMZN to AMZN_1min.csv\n",
            "\n",
            "--- Updating intraday data for NFLX ---\n",
            "--> Fetching REAL-TIME 30min data for NFLX...\n",
            "    [✔] Successfully fetched 100 rows for NFLX.\n",
            "    Merging data: Found 672 existing rows in NFLX_30min.csv.\n",
            "    Merge complete: Added 0 new unique row(s). Total rows: 672.\n",
            "    [✔] Successfully saved data for NFLX to NFLX_30min.csv\n",
            "--> Fetching REAL-TIME 1min data for NFLX...\n",
            "    [✔] Successfully fetched 100 rows for NFLX.\n",
            "    Merging data: Found 18662 existing rows in NFLX_1min.csv.\n",
            "    Merge complete: Added 2 new unique row(s). Total rows: 18664.\n",
            "    [✔] Successfully saved data for NFLX to NFLX_1min.csv\n",
            "\n",
            "--- Compact Intraday Data Update Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gap & Go Screener\n",
        "This command will run the gapgo.py script we just created. The script will load the data for each of your tickers, apply the Gap & Go trading logic, and print a message if it finds any valid setups. If any signals are found, it will save them to a new file: /data/signals/gapgo_signals.csv.\n",
        "\n",
        "What to Expect: The script will print its progress for each ticker. If it's outside of market hours, it will likely skip most tickers because there is no fresh pre-market or opening data."
      ],
      "metadata": {
        "id": "X_Eaus_icBtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/drive/MyDrive/trading-system/screeners/gapgo.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_12vrv07cIxm",
        "outputId": "3678f0f2-3bc6-49c0-ec7f-23ce77479c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 8 tickers from tickerlist.txt\n",
            "Verifying project directories...\n",
            "All directories are present in Google Drive.\n",
            "\n",
            "--- Running Gap & Go Screener (Execution-Grade) ---\n",
            "Current Market Session Detected: PREMARKET\n",
            "Saving 8 signal(s) from gapgo to /content/drive/MyDrive/trading-system/data/signals/gapgo_signals.csv...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10-Minute ORB Screener\n",
        "Description: This command runs the orb.py script. The script identifies stocks that break out of their first 10-minute opening range (9:30 - 9:40 AM EST). For best results, run this command at or after 9:41 AM EST. It will save any identified breakouts or breakdowns to /data/signals/orb_signals.csv."
      ],
      "metadata": {
        "id": "QmPN0Gp_isQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/drive/MyDrive/trading-system/screeners/orb.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yigT2ePviumO",
        "outputId": "eea9b39b-6910-42cd-c4c1-9dabc6f597d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 8 tickers from tickerlist.txt\n",
            "Verifying project directories...\n",
            "All directories are present in Google Drive.\n",
            "\n",
            "--- Running Opening Range Breakout (ORB) Screener ---\n",
            "Market session is PREMARKET. ORB screener only runs during REGULAR session.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find AVWAP Anchor Points\n",
        "\n",
        "This command runs the find_avwap_anchors.py job. It analyzes daily data to find significant \"power candles\" and saves them as anchor dates to /data/avwap_anchors.csv. Run this once before starting the main screener."
      ],
      "metadata": {
        "id": "79iwF2xPrOfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/drive/MyDrive/trading-system/jobs/find_avwap_anchors.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90fO9y0TrR-P",
        "outputId": "2d978065-2a02-4b68-d83f-76e117cf70a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 8 tickers from tickerlist.txt\n",
            "Verifying project directories...\n",
            "All directories are present in Google Drive.\n",
            "\n",
            "--- Running AVWAP Anchor Finder Job ---\n",
            "Successfully saved 8 detailed anchor sets to /content/drive/MyDrive/trading-system/data/avwap_anchors.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anchored VWAP Screener\n",
        "\n",
        "This command runs the avwap.py screener. It reads the pre-calculated anchor dates and checks for real-time reclaims or rejections of the AVWAP levels on high volume. It saves the results to /data/signals/avwap_signals.csv."
      ],
      "metadata": {
        "id": "owdAuAnWpzqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/drive/MyDrive/trading-system/screeners/avwap.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdZ8fRW5p3oO",
        "outputId": "948627df-06f1-401a-9b41-e182c45018a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 8 tickers from tickerlist.txt\n",
            "Verifying project directories...\n",
            "All directories are present in Google Drive.\n",
            "\n",
            "--- Running Anchored VWAP (AVWAP) Screener ---\n",
            "Saving 8 signal(s) from avwap to /content/drive/MyDrive/trading-system/data/signals/avwap_signals.csv...\n"
          ]
        }
      ]
    }
  ]
}