#!/usr/bin/env python3
"""
Complete Workflow Test
=====================

Test the complete real-time update workflow including:
1. Self-healing health check
2. Real-time data processing  
3. Intelligent append & resample logic
4. Production-grade error handling
"""

import os
import sys
import pandas as pd
import logging
from unittest.mock import Mock, patch

# Add project root to Python path
sys.path.append(os.path.abspath('.'))

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def test_complete_workflow():
    """Test the complete workflow from health check to data processing."""
    print("üöÄ Testing Complete Real-Time Update Workflow")
    print("=" * 60)
    
    # Mock the entire environment for testing
    with patch('jobs.compact_update.read_df_from_s3') as mock_read, \
         patch('jobs.compact_update.fetch_and_process_ticker') as mock_fetch, \
         patch('jobs.compact_update.save_ticker_data') as mock_save, \
         patch('jobs.compact_update.get_real_time_price') as mock_quote, \
         patch('jobs.compact_update.save_df_to_s3') as mock_save_s3:
        
        # Test Scenario 1: Healthy data (no self-healing needed)
        print("\nüìä Scenario 1: Healthy ticker (no repair needed)")
        
        # Mock healthy data
        healthy_df = pd.DataFrame({
            'timestamp': [f'2024-01-0{1 + i//390} {9 + (i%390)//60:02d}:{i%60:02d}:00' for i in range(2000)],
            'open': [100.0] * 2000,
            'high': [101.0] * 2000,
            'low': [99.0] * 2000,
            'close': [100.5] * 2000,
            'volume': [1000] * 2000
        })
        mock_read.return_value = healthy_df
        
        # Mock real-time quote
        mock_quote.return_value = {
            'price': 105.0,
            'volume': 1500
        }
        
        mock_save_s3.return_value = True
        
        try:
            from jobs.compact_update import process_ticker_realtime
            result = process_ticker_realtime("HEALTHY_TICKER")
            
            print(f"   Result: {result}")
            print(f"   Self-healing triggered: {mock_fetch.called}")
            print(f"   Real-time quote fetched: {mock_quote.called}")
            print(f"   Data saved: {mock_save_s3.called}")
            
            if result and mock_quote.called and not mock_fetch.called:
                print("   ‚úÖ Healthy ticker scenario PASSED")
                scenario1_passed = True
            else:
                print("   ‚ùå Healthy ticker scenario FAILED")
                scenario1_passed = False
                
        except Exception as e:
            print(f"   ‚ùå Error in healthy ticker scenario: {e}")
            scenario1_passed = False
        
        # Reset mocks for scenario 2
        mock_read.reset_mock()
        mock_fetch.reset_mock()
        mock_save.reset_mock()
        mock_quote.reset_mock()
        mock_save_s3.reset_mock()
        
        # Test Scenario 2: Corrupt data (self-healing needed)
        print("\nüîß Scenario 2: Corrupt ticker (self-healing required)")
        
        # Mock missing/corrupt data for initial health check
        mock_read.side_effect = [
            Exception("File not found"),  # First call - triggers self-healing
            healthy_df,  # Second call - repair verification  
            healthy_df   # Third call - Step 4 loading for real-time processing
        ]
        
        # Mock successful self-healing
        mock_fetch.return_value = {
            'daily': pd.DataFrame({'col': [1, 2]}),
            '30min': pd.DataFrame({'col': [1, 2]}),
            '1min': healthy_df
        }
        mock_save.return_value = {
            'saves_successful': 3,
            'saves_attempted': 3
        }
        
        # Mock real-time quote (should be called after successful repair)
        mock_quote.return_value = {
            'price': 107.0,
            'volume': 2000
        }
        
        mock_save_s3.return_value = True
        
        try:
            result = process_ticker_realtime("CORRUPT_TICKER")
            
            print(f"   Result: {result}")
            print(f"   Self-healing triggered: {mock_fetch.called}")
            print(f"   Repair data saved: {mock_save.called}")
            print(f"   Real-time quote fetched: {mock_quote.called}")
            print(f"   Updated data saved: {mock_save_s3.called}")
            
            if result and mock_fetch.called and mock_save.called and mock_quote.called:
                print("   ‚úÖ Corrupt ticker self-healing scenario PASSED")
                scenario2_passed = True
            else:
                print("   ‚ùå Corrupt ticker self-healing scenario FAILED")
                scenario2_passed = False
                
        except Exception as e:
            print(f"   ‚ùå Error in corrupt ticker scenario: {e}")
            scenario2_passed = False
        
        return scenario1_passed and scenario2_passed


def test_edge_cases():
    """Test edge cases and error handling."""
    print("\nüß™ Testing Edge Cases and Error Handling")
    print("-" * 50)
    
    edge_cases_passed = 0
    total_edge_cases = 3
    
    # Edge Case 1: API failure during real-time quote fetch
    print("\nüì° Edge Case 1: API failure during quote fetch")
    with patch('jobs.compact_update.read_df_from_s3') as mock_read, \
         patch('jobs.compact_update.get_real_time_price') as mock_quote:
        
        # Mock healthy data 
        healthy_df = pd.DataFrame({
            'timestamp': [f'2024-01-0{1 + i//390} {9 + (i%390)//60:02d}:{i%60:02d}:00' for i in range(2000)],
            'open': [100.0] * 2000,
            'high': [101.0] * 2000,
            'low': [99.0] * 2000,
            'close': [100.5] * 2000,
            'volume': [1000] * 2000
        })
        mock_read.return_value = healthy_df
        
        # Mock API failure
        mock_quote.return_value = None  # API returns no data
        
        try:
            from jobs.compact_update import process_ticker_realtime
            result = process_ticker_realtime("API_FAIL_TICKER")
            
            # Should handle gracefully and return True (not a processing failure)
            if result:
                print("   ‚úÖ API failure handled gracefully")
                edge_cases_passed += 1
            else:
                print("   ‚ùå API failure not handled properly")
                
        except Exception as e:
            print(f"   ‚ùå Exception during API failure test: {e}")
    
    # Edge Case 2: Self-healing repair failure
    print("\nüîß Edge Case 2: Self-healing repair failure")
    with patch('jobs.compact_update.read_df_from_s3') as mock_read, \
         patch('jobs.compact_update.fetch_and_process_ticker') as mock_fetch, \
         patch('jobs.compact_update.save_ticker_data') as mock_save:
        
        # Mock corrupt data
        mock_read.side_effect = Exception("File not found")
        
        # Mock repair failure
        mock_fetch.side_effect = Exception("API quota exceeded")
        
        try:
            result = process_ticker_realtime("REPAIR_FAIL_TICKER")
            
            # Should handle gracefully and return True (graceful skip)
            if result:
                print("   ‚úÖ Repair failure handled gracefully")
                edge_cases_passed += 1
            else:
                print("   ‚ùå Repair failure not handled properly")
                
        except Exception as e:
            print(f"   ‚ùå Exception during repair failure test: {e}")
    
    # Edge Case 3: File size validation edge case
    print("\nüìè Edge Case 3: File size validation")
    
    # Create small DataFrame (should trigger self-healing)
    small_df = pd.DataFrame({
        'timestamp': ['2024-01-01 10:00:00'],
        'open': [100.0],
        'high': [101.0],
        'low': [99.0],
        'close': [100.5],
        'volume': [1000]
    })
    
    # Estimate size (should be much less than 50KB)
    estimated_size = len(small_df) * 60  # 60 bytes per row estimate
    print(f"   Small DataFrame size estimate: {estimated_size} bytes")
    
    if estimated_size < 50 * 1024:  # Less than 50KB
        print("   ‚úÖ File size validation logic correct")
        edge_cases_passed += 1
    else:
        print("   ‚ùå File size validation logic incorrect")
    
    print(f"\nüìä Edge Cases: {edge_cases_passed}/{total_edge_cases} passed")
    return edge_cases_passed == total_edge_cases


def main():
    """Run complete workflow tests."""
    print("üß™ COMPLETE WORKFLOW TEST SUITE")
    print("=" * 60)
    
    tests_passed = 0
    total_tests = 2
    
    # Test 1: Complete workflow
    if test_complete_workflow():
        tests_passed += 1
        print("\n‚úÖ COMPLETE WORKFLOW TEST: PASSED")
    else:
        print("\n‚ùå COMPLETE WORKFLOW TEST: FAILED")
    
    # Test 2: Edge cases
    if test_edge_cases():
        tests_passed += 1
        print("\n‚úÖ EDGE CASES TEST: PASSED")
    else:
        print("\n‚ùå EDGE CASES TEST: FAILED")
    
    print("\n" + "=" * 60)
    print(f"üèÅ FINAL RESULTS: {tests_passed}/{total_tests} test suites passed")
    
    if tests_passed == total_tests:
        print("üéâ ALL TESTS PASSED! Self-healing real-time update engine is production-ready!")
        print("\nüìã Implementation Summary:")
        print("   ‚úÖ Self-healing health check with automatic full_fetch repair")
        print("   ‚úÖ Real-time data processing with GLOBAL_QUOTE endpoint")
        print("   ‚úÖ Intelligent append & resample logic preserved")
        print("   ‚úÖ Production-grade error handling")
        print("   ‚úÖ Graceful handling of API failures and edge cases")
        return True
    else:
        print("‚ö†Ô∏è Some tests failed. Implementation needs review.")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)